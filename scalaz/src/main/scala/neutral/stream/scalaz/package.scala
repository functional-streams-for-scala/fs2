package neutral.stream

import neutral.stream.ReceiveY.ReceiveT
import scodec.bits.ByteVector

import _root_.scalaz._
import _root_.scalaz.concurrent.Task
import _root_.scalaz.syntax.{FunctorOps, ApplyOps, ApplicativeOps, MonadOps}
import _root_.scalaz.syntax.all._

import neutral.stream.Cause._
import neutral.stream.Process._
import neutral.stream.process1._

package object scalaz extends ProcessInstances with ReceiveYInstances {
  implicit val byteVectorSemigroupInstance: Semigroup[ByteVector] =
    Semigroup.instance(_ ++ _)

  implicit class ProcessSyntax[F[_], O](val self: Process[F, O]) extends AnyVal {
    /**
     * Map over this `Process` to produce a stream of `F`-actions,
     * then evaluate these actions in batches of `bufSize`, allowing
     * for nondeterminism in the evaluation order of each action in the
     * batch.
     */
    def gatherMap[F2[x]>:F[x],O2](bufSize: Int)(f: O => F2[O2])(
      implicit F: Nondeterminism[F2]): Process[F2,O2] =
      self.map(f).gather(bufSize)

    /**
     * Catch some of the exceptions generated by this `Process`, rethrowing any
     * not handled by the given `PartialFunction` and stripping out any values
     * emitted before the error.
     */
    def handle[F2[x]>:F[x],O2](f: PartialFunction[Throwable, Process[F2,O2]])(implicit F: Catchable[F2]): Process[F2, O2] =
      self.attempt(rsn => f.lift(rsn).getOrElse(self.fail(rsn)))
        .dropWhile(_.isRight)
        .map(_.fold(identity, _ => sys.error("unpossible")))

    /**
     * Like `attempt`, but accepts a partial function. Unhandled errors are rethrown.
     */
    def partialAttempt[F2[x]>:F[x],O2](f: PartialFunction[Throwable, Process[F2,O2]])
      (implicit F: Catchable[F2]): Process[F2, O2 \/ O] =
      self.attempt(err => f.lift(err).getOrElse(self.fail(err)))

    /** Translate the request type from `F` to `G`, using the given polymorphic function. */
    def translate[G[_]](f: F ~> G): Process[G,O] =
      this.suspendStep.flatMap {
        case Step(Emit(os),cont) => emitAll(os) +: cont.extend(_.translate(f))
        case Step(Await(req,rcv),cont) =>
          Await[G,Any,O](f(req), r => {
            Trampoline.suspend(rcv(r)).map(_ translate f)
          }) +: cont.extend(_.translate(f))
        case hlt@Halt(rsn) => hlt
      }

    ///////////////////////////////////////////
    //
    // Interpreters, runXXX
    //
    ///////////////////////////////////////////

    /**
     * Collect the outputs of this `Process[F,O]` into a Monoid `B`, given a `Monad[F]` in
     * which we can catch exceptions. This function is not tail recursive and
     * relies on the `Monad[F]` to ensure stack safety.
     */
    final def runFoldMap[F2[x] >: F[x], B](f: O => B)(implicit F: Monad[F2], C: Catchable[F2], B: Monoid[B]): F2[B] = {
      def go(cur: Process[F2, O], acc: B): F2[B] = {
        cur.step match {
          case s: Step[F2,O]@unchecked =>
            (s.head, s.next) match {
              case (Emit(os), cont) =>
                F.bind(F.point(os.foldLeft(acc)((b, o) => B.append(b, f(o))))) { nacc =>
                  go(cont.continue.asInstanceOf[Process[F2,O]], nacc)
                }
              case (awt:Await[F2,Any,O]@unchecked, cont) =>
                F.bind(C.attempt(awt.req)) { r =>
                  go((Try(awt.rcv(EarlyCause(r)).run) +: cont).asInstanceOf[Process[F2,O]]
                    , acc)
                }
            }
          case Halt(End) => F.point(acc)
          case Halt(Kill) => F.point(acc)
          case Halt(Error(rsn)) => C.fail(rsn)
        }
      }

      go(this, B.zero)
    }


    /**
     * Collect the outputs of this `Process[F,O]`, given a `Monad[F]` in
     * which we can catch exceptions. This function is not tail recursive and
     * relies on the `Monad[F]` to ensure stack safety.
     */
    final def runLog[F2[x] >: F[x], O2 >: O](implicit F: Monad[F2], C: Catchable[F2]): F2[IndexedSeq[O2]] = {
      F.map(runFoldMap[F2, Vector[O2]](Vector(_))(
        F, C,
        // workaround for performance bug in Vector ++
        Monoid.instance[Vector[O2]]((a, b) => a fast_++ b, Vector())
      ))(_.toIndexedSeq)
    }

    /** Run this `Process` solely for its final emitted value, if one exists. */
    final def runLast[F2[x] >: F[x], O2 >: O](implicit F: Monad[F2], C: Catchable[F2]): F2[Option[O2]] =
      F.map(this.last.runLog[F2,O2])(_.lastOption)

    /** Run this `Process` solely for its final emitted value, if one exists, using `o2` otherwise. */
    final def runLastOr[F2[x] >: F[x], O2 >: O](o2: => O2)(implicit F: Monad[F2], C: Catchable[F2]): F2[O2] =
      F.map(this.last.runLog[F2,O2])(_.lastOption.getOrElse(o2))

    /** Run this `Process`, purely for its effects. */
    final def run[F2[x] >: F[x]](implicit F: Monad[F2], C: Catchable[F2]): F2[Unit] =
      F.void(drain.runLog(F, C))
  }

  implicit class EvalProcessSyntax[F[_], O](val self: Process[F, F[O]]) extends AnyVal {
    /**
     * Read chunks of `bufSize` from input, then use `Nondeterminism.gatherUnordered`
     * to run all these actions to completion.
     */
    def gather(bufSize: Int)(implicit F: Nondeterminism[F]): Process[F, O] =
      self.pipe(process1.chunk(bufSize)).map(F.gatherUnordered).eval.flatMap(emitAll)

    /**
     * Read chunks of `bufSize` from input, then use `Nondeterminism.gather`
     * to run all these actions to completion and return elements in order.
     */
    def sequence(bufSize: Int)(implicit F: Nondeterminism[F]): Process[F, O] =
      self.pipe(process1.chunk(bufSize)).map(F.gather).eval.flatMap(emitAll)
  }

  /** Adds syntax for `Channel`. */
  implicit class ChannelSyntax[F[_],I,O](val self: Channel[F,I,O]) extends AnyVal {
    /** Transform the output of this `Channel` */
    def mapOut[O2](f: O => O2)(implicit F: Functor[F]): Channel[F,I,O2] =
      self.map(_ andThen F.lift(f))
  }

  /** Adds syntax for `Sink`. */
  implicit class SinkSyntax[F[_],I](val self: Sink[F,I]) extends AnyVal {
    /** Converts `Sink` to `Channel`, that will perform the side effect and echo its input. */
    def toChannel(implicit F: Functor[F]): Channel[F,I,I] =
      self.map(f => (i: I) => F.map(f(i))(_ => i))
  }

  /** Syntax for Sink, that is specialized for Task */
  implicit class SinkTaskSyntax[I](val self: Sink[Task,I]) extends AnyVal {
    /** converts sink to sink that first pipes received `I0` to supplied p1 */
    def pipeIn[I0](p1: Process1[I0, I]): Sink[Task, I0] = Process.suspend {
      // Note: Function `f` from sink `self` may be used for more than 1 element emitted by `p1`.
      @volatile var cur = p1.step
      @volatile var lastF: Option[I => Task[Unit]] = None
      self.takeWhile { _ =>
        cur match {
          case Halt(Cause.End) => false
          case Halt(cause)     => throw new Cause.Terminated(cause)
          case _               => true
        }
      } map { (f: I => Task[Unit]) =>
        lastF = Some(f)
        (i0: I0) => Task.suspend {
          cur match {
            case Halt(_) => sys.error("Impossible")
            case Step(Emit(piped), cont) =>
              cur = process1.feed1(i0) { cont.continue }.step
              piped.toList.traverse_(f)
            case Step(hd, cont) =>
              val (piped, tl) = process1.feed1(i0)(hd +: cont).unemit
              cur = tl.step
              piped.toList.traverse_(f)
          }
        }
      } onHalt {
        case Cause.Kill =>
          lastF map { f =>
            cur match {
              case Halt(_) => sys.error("Impossible (2)")
              case s@Step(_, _) =>
                s.toProcess.disconnect(Cause.Kill).evalMap(f).drain
            }
          } getOrElse Halt(Cause.Kill)
        case Cause.End  => halt
        case c@Cause.Error(_) => halt.causedBy(c)
      }
    }
  }

  implicit def toMonadOps[X:Monoid,A](f: ReceiveY[X,A]): MonadOps[ReceiveT[X]#f,A] =
    receiveYInstance.monadSyntax.ToMonadOps(f)
  implicit def toApplicativeOps[X:Monoid,A](f: ReceiveY[X,A]): ApplicativeOps[ReceiveT[X]#f,A] =
    receiveYInstance.applicativeSyntax.ToApplicativeOps(f)
  implicit def toApplyOps[X:Monoid,A](f: ReceiveY[X,A]): ApplyOps[ReceiveT[X]#f,A] =
    receiveYInstance.applySyntax.ToApplyOps(f)
  implicit def toFunctorOps[X:Monoid,A](f: ReceiveY[X,A]): FunctorOps[ReceiveT[X]#f,A] =
    receiveYInstance.functorSyntax.ToFunctorOps(f)


  /**
   * Emits only elements that are distinct from their immediate predecessors.
   *
   * @example {{{
   * scala> import scalaz.std.anyVal._
   * scala> Process(1, 2, 2, 1, 1, 3).distinctConsecutive.toList
   * res0: List[Int] = List(1, 2, 1, 3)
   * }}}
   */
  def distinctConsecutive[A: Equal]: Process1[A, A] =
    distinctConsecutiveBy(identity)

  /**
   * Emits only elements that are distinct from their immediate predecessors
   * according to `f`.
   *
   * @example {{{
   * scala> import scalaz.std.anyVal._
   * scala> Process("a", "ab", "bc", "c", "d").distinctConsecutiveBy(_.length).toList
   * res0: List[String] = List(a, ab, c)
   * }}}
   */
  def distinctConsecutiveBy[A, B: Equal](f: A => B): Process1[A, A] =
    filterBy2((a1, a2) => f(a1) =/= f(a2))


  /** Alias for `[[reduceMap]](f)(M)`. */
  def fold1Map[A, B](f: A => B)(implicit M: Monoid[B]): Process1[A, B] =
    reduceMap(f)(M)

  /** Alias for `[[reduceSemigroup]](M)`. */
  def fold1Monoid[A](implicit M: Monoid[A]): Process1[A, A] =
    reduceSemigroup(M)

  /**
   * Like `fold` only uses `f` to map `A` to `B` and uses Monoid `M` for associative operation
   */
  def foldMap[A, B](f: A => B)(implicit M: Monoid[B]): Process1[A, B] =
   lift(f).foldMonoid(M)

  /**
   * Like `fold` but uses Monoid for folding operation
   */
  def foldMonoid[A](implicit M: Monoid[A]): Process1[A, A] =
    fold(M.zero)(M.append(_, _))

  /** Alias for `[[reduceSemigroup]](M)`. */
  def foldSemigroup[A](implicit M: Semigroup[A]): Process1[A, A] =
    reduceSemigroup(M)


  /** Emits the greatest element of the input. */
  def maximum[A](implicit A: Order[A]): Process1[A,A] =
    reduce((x, y) => if (A.greaterThan(x, y)) x else y)

  /** Emits the element `a` of the input which yields the greatest value of `f(a)`. */
  def maximumBy[A,B: Order](f: A => B): Process1[A,A] =
    reduce((x, y) => if (Order.orderBy(f).greaterThan(x, y)) x else y)

  /** Emits the greatest value of `f(a)` for each element `a` of the input. */
  def maximumOf[A,B: Order](f: A => B): Process1[A,B] =
    lift(f).maximum

  /** Emits the smallest element of the input. */
  def minimum[A](implicit A: Order[A]): Process1[A,A] =
    reduce((x, y) => if (A.lessThan(x, y)) x else y)

  /** Emits the element `a` of the input which yields the smallest value of `f(a)`. */
  def minimumBy[A,B: Order](f: A => B): Process1[A,A] =
    reduce((x, y) => if (Order.orderBy(f).lessThan(x, y)) x else y)

  /** Emits the smallest value of `f(a)` for each element `a` of the input. */
  def minimumOf[A,B: Order](f: A => B): Process1[A,B] =
    lift(f).minimum

  /**
   * Like `reduce` only uses `f` to map `A` to `B` and uses Semigroup `M` for
   * associative operation.
   */
  def reduceMap[A, B](f: A => B)(implicit M: Semigroup[B]): Process1[A, B] =
    lift(f).reduceSemigroup(M)

  /** Alias for `[[reduceSemigroup]](M)`. */
  def reduceMonoid[A](implicit M: Monoid[A]): Process1[A, A] =
    reduceSemigroup(M)

  /** Like `reduce` but uses Semigroup `M` for associative operation. */
  def reduceSemigroup[A](implicit M: Semigroup[A]): Process1[A, A] =
    reduce(M.append(_, _))

  /**
   * Repartitions the input with the function `p`. On each step `p` is applied
   * to the input and all elements but the last of the resulting sequence
   * are emitted. The last element is then prepended to the next input using the
   * Semigroup `I`. For example,
   * {{{
   * scala> import scalaz.std.string._
   * scala> Process("Hel", "l", "o Wor", "ld").repartition(_.split(" ")).toList
   * res0: List[String] = List(Hello, World)
   * }}}
   */
  def repartition[I](p: I => IndexedSeq[I])(implicit I: Semigroup[I]): Process1[I, I] = {
    def go(carry: Option[I]): Process1[I, I] =
      receive1Or[I,I](emitAll(carry.toList)) { i =>
        val next = carry.fold(i)(c => I.append(c, i))
        val parts = p(next)
        parts.size match {
          case 0 => go(None)
          case 1 => go(Some(parts.head))
          case _ => emitAll(parts.init) ++ go(Some(parts.last))
        }
      }
    go(None)
  }

  /**
   * Repartitions the input with the function `p`. On each step `p` is applied
   * to the input and the first element of the resulting tuple is emitted if it
   * is `Some(x)`. The second element is then prepended to the next input using
   * the Semigroup `I`. In comparison to `repartition` this allows to emit
   * single inputs without prepending them to the next input.
   */
  def repartition2[I](p: I => (Option[I], Option[I]))(implicit I: Semigroup[I]): Process1[I,I] = {
    def go(carry: Option[I]): Process1[I,I] =
      receive1Or[I,I](emitAll(carry.toList)) { i =>
        val next = carry.fold(i)(c => I.append(c, i))
        val (fst, snd) = p(next)
        fst.fold(go(snd))(head => emit(head) ++ go(snd))
      }
    go(None)
  }

  /**
   * Like `scan1` only uses `f` to map `A` to `B` and uses Semigroup `M` for
   * associative operation.
   */
  def scan1Map[A, B](f: A => B)(implicit M: Semigroup[B]): Process1[A, B] =
    lift(f).scanSemigroup(M)

  /** Alias for `[[scanSemigroup]](M)`. */
  def scan1Monoid[A](implicit M: Monoid[A]): Process1[A, A] =
    scanSemigroup(M)

  /**
   * Like `scan` only uses `f` to map `A` to `B` and uses Monoid `M` for associative operation
   */
  def scanMap[A, B](f: A => B)(implicit M: Monoid[B]): Process1[A, B] =
    lift(f).scanMonoid(M)

  /**
   * Like `scan` but uses Monoid for associative operation
   */
  def scanMonoid[A](implicit M: Monoid[A]): Process1[A, A] =
    scan(M.zero)(M.append(_, _))

  /** Like `scan1` but uses Semigroup `M` for associative operation. */
  def scanSemigroup[A](implicit M: Semigroup[A]): Process1[A, A] =
    scan1(M.append(_, _))

  /**
   * Break the input into chunks where the input is equal to the given delimiter.
   * The delimiter does not appear in the output. Two adjacent delimiters in the
   * input result in an empty chunk in the output.
   */
  def splitOn[I: Equal](i: I): Process1[I, Vector[I]] =
    split(_ === i)
}
